# results/ â€” Raw LLM Output Logs (JSON Lines)

This directory contains **raw responses generated by LLMs** during Phase 2 of **Research Task 8: Bias Detection in LLM Narratives**.

Responses are stored in structured JSONL format for:

- Reproducibility  
- Auditing  
- Downstream analysis (sentiment, focus, bias metrics)  
- Claim validation (via validate_claims.py)

---

## Files

raw_responses.jsonl
validation_report.csv

yaml
Copy code

> Note:  
> This folder may be large. If GitHub storage limits are exceeded, remove the JSONL file and document how to regenerate it.

---

## Example JSONL Record

```json
{
  "id": "4a3fbb19-3220-4f73-8290-1123dce8c1c4",
  "timestamp": "2025-10-23T21:14:55Z",
  "model": "mock",
  "model_version": "mock-llm",
  "temperature": 0.3,
  "hypothesis": "H3",
  "variant": "positive",
  "prompt_path": "prompts/H3_positive.txt",
  "prompt_text": "...",
  "response_text": "The data shows strong offensive upside..."
